# 数据库

[TOC]

# 数据库底层数据结构

> 参考资料：https://zhuanlan.zhihu.com/p/113917726

## 为什么数据库不使用**链地址法哈希表**作为底层结构

考虑到数据检索有一个常用手段就是范围查找，比如以下这个 SQL 语句：

```mysql
select * from user where id >3;
```

如果使用哈希算法实现的索引，范围查找怎么做呢？一个简单的思路就是一次把所有数据找出来加载到内存，然后再在内存里筛选筛选目标范围内的数据。但是这个范围查找的方法也太笨重了，没有一点效率而言。

所以，使用哈希算法实现的索引虽然**可以做到快速检索数据**，但是**没办法做数据高效范围查找**，因此哈希索引是不适合作为 Mysql 的底层索引的数据结构。



## 为什么不使用红黑树作为底层结构

二叉搜索树可以实现范围查找：二叉树的叶子节点都是按序排列的，从左到右依次升序排列，如果我们需要找 id>5 的数据，那我们取出节点为 6 的节点以及其右子树就可以了，范围查找也算是比较容易实现。

<img src="../../../E/typora/Pictures/v2-032790aff0ddf52b676413573acce776_720w.jpg" alt="img" style="zoom: 50%;" />

在数据库中递增数据插入的情况很多，当出现这种情况时，二叉搜索树和红黑树会出现"右倾"的趋势，**红黑树并没有完全解决二叉查找树的“右倾问题”**，虽然这个“右倾”趋势远没有二叉查找树退化为线性链表那么夸张。，但是数据库中的基本主键自增操作，主键一般都是数百万数千万的，如果红黑树存在这种问题，对于查找性能而言也是巨大的消耗，我们数据库不可能忍受这种无意义的等待的。

![img](../../../E/typora/Pictures/v2-60cea4af963b156ee5f40030977ab77c_720w.jpg)

## 为什么不使用平衡二叉树（AVL）

总结一下 AVL 树的优点：

1. 不错的查找性能（O（logn）），不存在极端的低效查找的情况。
2. 可以实现范围查找、数据排序。

<img src="../../../E/typora/Pictures/v2-0dad51645707e973b152e44e4b7479c5_720w.jpg" alt="img" style="zoom:50%;" />

**数据库查询数据的瓶颈在于磁盘 IO**，如果使用的是 AVL 树，我们**每一个树节点只存储了一个数据**，我们一次磁盘 IO **只能取出来一个节点上的数据加载到内存里**，那比如查询 id=7 这个数据我们就要进行磁盘 IO 三次，这是多么消耗时间的。所以我们设计数据库索引时需要首先考虑**怎么尽可能减少磁盘 IO 的次数**。

磁盘 IO 有个有个特点，就是从磁盘读取 **1B** 数据和 **1KB** 数据所消耗的时间是基本一样的，我们就可以根据这个思路，我们可以**在一个树节点上尽可能多地存储数据**，**一次磁盘 IO 就多加载点数据到内存**，这就是 B 树，B+树的的设计原理了。

# MySQL

## 逻辑架构

### MySQL逻辑架构

> 参考资料：https://www.cnblogs.com/baochuan/archive/2012/03/15/2397536.html

<img src="../../../E/typora/Pictures/2012031510324452.png" alt="img" style="zoom:67%;" />

每个虚线框为一层，总共三层。

第一层，连接层(为客户端服务):为请求做**连接处理**，**授权认证**，**安全**等。

第二层，服务层:**查询解析**，**分析**，**优化**，**缓存**，提供内建函数;存储过程，触发器，视图。

第三层，存储引擎层，不光做存储和提取数据，而且针对特殊数据引擎还要做事务处理。

### 事务

**事务是一组原子性的 SQL 查询**，或者说一个独立的工作单元。如果数据库引擎能够成功地对数据库应用该组查询的全部语句，那么就执行该组查询。如果其中有任何一条语句因为崩溃或其他原因无法执行，那么所有的语句都不会执行。也就是说**事务内的语句要么全部执行成功，要么全部执行失败**。

### 事务特性（ACID）

**原子性** **atomicity**

一个事务在逻辑上是必须不可分割的最小工作单元，整个事务中的所有操作要么全部提交成功，要么全部失败回滚，对于一个事务来说不可能只执行其中的一部分。

**一致性** **consistency**

数据库总是从一个一致性的状态转换到另一个一致性的状态。

**隔离性** **isolation**

针对并发事务而言，隔离性就是要隔离并发运行的多个事务之间的相互影响，**一般来说一个事务所做的修改在最终提交以前，对其他事务是不可见的**。

**持久性** **durability**

一旦事务提交成功，其修改就会永久保存到数据库中，此时即使系统崩溃，修改的数据也不会丢失。

#### mysql ACID的实现

> 参考资料：https://www.cnblogs.com/kismetv/p/10331633.html

- 原子性：语句要么全执行，要么全不执行，是事务最核心的特性，事务本身就是以原子性来定义的；实现主要基于undo log
- 持久性：保证事务提交后不会因为宕机等原因导致数据丢失；实现主要基于redo log
- 隔离性：保证事务执行尽可能不受其他事务影响；InnoDB默认的隔离级别是RR，RR的实现主要基于锁机制（包含next-key lock）、MVCC（包括数据的隐藏列、基于undo log的版本链、ReadView）
- 一致性：事务追求的最终目标，一致性的实现既需要数据库层面的保障（以上三个性质保障），也需要应用层面的保障

#### UNDO机制

> 参考资料：https://segmentfault.com/a/1190000017888478
>
> https://yq.aliyun.com/articles/592937

每个事务提交前将数据和Undo Log写入磁盘，这样会导致大量的磁盘IO，因此性能很低。如果能够将数据缓存一段时间，就能减少IO提高性能。但是这样就会丧失事务的持久性。因此引入了另外一种机制来实现持久化，即Redo Log。

为了降低复杂度，InnoDB将Undo Log看作数据，因此记录Undo Log的操作也会记录到Redo Log中。这样undo log就可以象数据一样缓存起来，而不用在redo log之前写入磁盘了。

一个被回滚了的事务在恢复时的操作就是先redo再undo，因此不会破坏数据的一致性。

在InnoDB内存中，一般的顺序如下：

- 写undo的redo
- 写undo
- 修改数据页
- 写Redo

#### REDO机制

> 参考资料：https://juejin.cn/post/6844904117706440718（写的很好）

MySQL 在更新数据时，为了减少磁盘的随机 IO，因此并不会直接更新磁盘上的数据，而是先更新 Buffer Pool 中**缓存页**的数据，等到合适的时间点，再将这个缓存页持久化到磁盘。而 Buffer Pool 中所有缓存页都是处于内存当中的，当 MySQL 宕机或者机器断电，内存中的数据就会丢失，因此 MySQL 为了防止缓存页中的数据在更新后出现数据丢失的现象，引入了 redo log 机制。



REDO log 是先写入一个叫做 **redo log buffer 的内存缓存**中，，它是 redo log 日志缓冲区，默认大小是 16MB。redo log buffer 内部又可以划分为许多 redo log block，每个 redo log block 大小为 512 字节。我们写入的 redo log 日志，最终实际上是先写入在 redo log buffer 的 redo log block 中，然后在某一个合适的时间点，将这条 redo log 所在的 redo log block 刷入到磁盘中。

这个合适的时间点究竟是什么时候呢？

1. MySQL 正常关闭的时候；
2. MySQL 的后台线程每隔一段时间定时的将 redo log buffer 刷入到磁盘，默认是每隔 1s 刷一次；
3. 当 redo log buffer 中的日志写入量超过 redo log buffer 内存的一半时，即超过 8MB 时，会触发 redo log buffer 的刷盘；
4. 当事务提交时，根据配置的参数 innodb_flush_log_at_trx_commit 来决定是否刷盘。如果 innodb_flush_log_at_trx_commit 参数配置为 0，表示事务提交时，不进行 redo log buffer 的刷盘操作；如果配置为 1，表示事务提交时，会将此时事务所对应的 redo log 所在的 redo log block 从内存写入到磁盘，同时调用 fysnc，确保数据落入到磁盘；如果配置为 2，表示只是将日志写入到操作系统的缓存，而不进行 fysnc 操作。（进程在向磁盘写入数据时，是先将数据写入到操作系统的缓存中：os cache，再调用 fsync 方法，才会将数据从 os cache 中刷新到磁盘上）





每次更新数据时，最终还是要将 redo log 写入到磁盘，也就是还是会发生一次磁盘 IO，而我为什么不直接停止使用 redo log，而在每次更新数据时，也不要直接更新内存了，直接将数据更新到磁盘，这样也是发生了一次磁盘 IO，何必引入 redo log 这一机制呢？

答：

1. 将 redo log 日志追加到文件末尾，虽然也是一次磁盘 IO，但是这是顺序写操作（不需要移动磁头）
2. 通常一次更新操作，我们往往只会涉及到修改几个字节的数据，因为仅仅修改几个字节的数据，就将整个数据页写入到磁盘代价太大。redo log日志大小可能就几个字节，写入磁盘代价小。

### 脏读、不可重复读、和幻读

> 参考资料：https://cloud.tencent.com/developer/article/1450773

**脏读（读取未提交数据）**

A事务读取B事务尚未提交的数据，此时如果B事务发生错误并执行回滚操作，那么A事务读取到的数据就是脏数据。

<img src="../../../E/typora/Pictures/image-20210105213440285.png" alt="image-20210105213440285" style="zoom: 50%;" />

**不可重复读（前后多次读取，数据内容不一致）**

事务A在执行读取操作，由整个事务A比较大，前后读取同一条数据需要经历很长的时间 。而在事务A第一次读取数据，比如此时读取了小明的年龄为20岁，事务B执行更改操作，将小明的年龄更改为30岁，此时事务A第二次读取到小明的年龄时，发现其年龄是30岁，和之前的数据不一样了，也就是数据不重复了，系统不可以读取到重复的数据，成为不可重复读。

<img src="../../../E/typora/Pictures/image-20210105213622096.png" alt="image-20210105213622096" style="zoom:50%;" />

**幻读（前后多次读取，数据总量不一致）**

事务A在执行读取操作，需要两次统计数据的总量，前一次查询数据总量后，此时事务B执行了新增数据的操作并提交后，这个时候事务A读取的数据总量和之前统计的不一样，就像产生了幻觉一样，平白无故的多了几条数据，成为幻读。

<img src="../../../E/typora/Pictures/image-20210105213651496.png" alt="image-20210105213651496" style="zoom:50%;" />

**不可重复读和幻读到底有什么区别呢？**

(1) 不可重复读是读取了其他事务更改的数据，**针对update操作**

解决：使用行级锁，锁定该行，事务A多次读取操作完成后才释放该锁，这个时候才允许其他事务更改刚才的数据。

(2) 幻读是读取了其他事务新增的数据，**针对insert和delete操作**

解决：在读取的每一行数据上都加锁，可能导致大量的超时和锁争用的问题。实际应用中很少用到这个隔离级别

### MySQL的隔离级别

|                                                   | 脏读 | 不可重复读 | 幻读 |
| ------------------------------------------------- | ---- | ---------- | ---- |
| Read Uncommitted（读未提交）                      | √    | √          | √    |
| Read Committed（提交读）                          | ×    | √          | √    |
| Repeatable Read （可重复读）【MySQL默认隔离级别】 | ×    | ×          | √    |
| Serializable （可串行化）                         | ×    | ×          | ×    |

### InnoDB锁机制

> 参考资料：
>
> https://segmentfault.com/a/1190000014133576
>
> https://www.zhihu.com/question/51513268

<img src="../../../E/typora/Pictures/1460000014133582" alt="这里写图片描述" style="zoom: 67%;" />

1. InnoDB支持多种锁粒度，**默认使用行锁**，锁粒度最小，锁冲突发生的概率最低，支持的并发度也最高，但系统消耗成本也相对较高；由于MVCC机制，上了行读/写锁，其他事务还可以进行读操作
2. InnoDB有三种锁算法——record记录锁、gap间隙锁、还有结合了记录锁与间隙锁的next-key锁（可参考：http://zhongmingmao.me/2017/05/18/innodb-next-key-lock/）
3. InnoDB所有的行锁算法都是基于索引实现的，锁定的也都是索引或索引区间

**乐观锁与悲观锁**

乐观锁会“乐观地”假定大概率不会发生并发更新冲突，访问、处理数据过程中不加锁，只在更新数据时再根**据版本号或时间戳**判断是否有冲突，有则处理，无则提交事务；

悲观锁会“悲观地”假定大概率会发生并发更新冲突，访问、处理数据前就加排他锁，在整个数据处理过程中锁定数据，**事务提交或回滚后才释放锁**；



**共享锁与互斥锁**

| 行锁类型            | 锁功能                             | 锁兼容性                   | 加锁                                                         | 释放锁                                                       |
| ------------------- | ---------------------------------- | -------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 共享锁（读锁、S锁） | 允许获取共享锁的事务读数据         | 与共享锁兼容与排它锁不兼容 | 只有**Serializable**隔离级别默认为读加共享锁；其他割裂级别下可以**显式**使用select...**lock in share mode**为读加共享锁 | 在**事务提交或回滚**后会自动同时释放锁；<br />除了使用start transaction的方式显式开启事务，InnoDB也会自动为增删改查语句开启事务，并自动提交或回滚。 |
| 互斥锁（写锁、X锁） | 允许获取排它锁的事务更新或删除数据 | 与共享锁和排它锁都不兼容   | 在默认的**Reapeatable Read**隔离级别下，InnoDB会自动为增删改操作的行加排它锁；也可以显式用select...**for update**为读加排它锁 | 同上                                                         |



**当前读与快照读**

**1、当前读：即加锁读**，读取记录的最新版本，会加锁保证其他并发事务不能修改当前记录，直至获取锁的事务释放锁；

**2、快照读：即不加锁读**，读取记录的**快照版本**而非最新版本，通过**MVCC实现**；



**意向锁**

- 意向锁包括IX（意向互斥锁）和IS（意向共享锁），**IX，IS是表级锁，不会和行级的X，S锁发生冲突。只会和表级的X，S发生冲突**
- 意向锁是在添加行锁之前添加到表上，如果添加成功，则接着尝试添加对应的行锁。这样无需遍历整个表，添加表级的X，S锁即可获取添加是否成功的结果。

### MVCC（Multiple Version Concurrent Control 多版本并发控制）

> 参考资料：
>
> https://segmentfault.com/a/1190000014133576
>
> https://blog.csdn.net/luzhensmart/article/details/88134189

MVCC的最大好处：读不加任何锁，读写不冲突，对于读操作多于写操作的应用，极大的增加了系统的并发性能；

InnoDB默认的RR事务隔离级别下，不显式加『lock in share mode』与『for update』的『select』操作都属于快照读，使用MVCC，保证事务执行过程中只有第一次读之前提交的修改和自己的修改可见，其他的均不可见；

InnoDB是用MVCC解决了**脏读**和**不可重复读**和**快照读情况下的幻读**，而**当前读情况下幻读**的问题需要next-key锁解决。

**MVCC理论**

InnoDB的MVCC，是通过在每行记录后面保存**两个隐藏的列**来实现的。这两个列，一个保存了**行的创建时间（行版本号）**，一个保存行的**过期时间（删除标识)**。当然存储的并不是实际的时间值，而是**系统版本号**(system version number)。每开始一个新的事务，系统版本号都会自动递增。事务开始时刻的系统版本号会作为事务的版本号，用来和查询到的每行记录的版本号进行比较。下面看一下在REPEATABLE READ隔离级别下，MVCC具体是如何操作的。
**SELECT**

InnoDB会根据以下两个条件检查每行记录:

1. InnoDB只查找**版本早于当前事务版本的数据行**（也就是，行的系统版本号小．于或等于事务的系统版本号)，这样可以确保事务读取的行，要么是在事务开始前已经存在的，要么是事务自身插入或者修改过的。

2. 查找的行的**删除版本**要么**未定义**，要么大于当前事务版本号。这可以确保事务读取到的行，在事务开始之前未被删除。只有符合上述两个条件的记录，才能返回作为查询结果。

**INSERT**

InnoDB为新插入的每一行保存**当前系统版本号**作为**行版本号**。

**DELETE**

InnoDB为删除的每一行保存**当前系统版本号**作为**行删除标识**。

**UPDATE**

InnoDB为插入一行新记录，保存当前系统版本号作为行版本号，同时保存当前系统版本号到原来的行作为行删除标识。（相当于插入+删除）

保存这两个额外系统版本号，**使大多数读操作都可以不用加锁**。这样设计使得读数据操作很简单，性能很好，并且也能保证只会读取到符合标准的行。不足之处是每行记录都需要额外的存储空间，需要做更多的行检查工作，以及一些额外的维护工作。

MVCC 只在REPEATABLE READ和READ COMMITTED两个隔离级别下工作。其他两个隔离级别都和MVCC不兼容，因为READ UNCOMMITTED总是读取最新的数据行，而不是符合当前事务版本的数据行。而SERIALIZABLE则会对所有读取的行都加锁。

#### InnoDB的MVCC

> 参考资料：https://www.cnblogs.com/kismetv/p/10331633.html

InnoDB实现MVCC，多个版本的数据可以共存，主要基于以下技术及数据结构：

1. 隐藏列：InnoDB中每行数据都有隐藏列，隐藏列中包含了本行数据的**事务id**、**指向undo log的指针**等。

2. 基于undo log的版本链：前面说到每行数据的隐藏列中包含了指向undo log的指针，而每条undo log也会指向更早版本的undo log，从而形成一条版本链。

3. ReadView：通过隐藏列和版本链，MySQL可以将数据恢复到指定版本；但是具体要恢复到哪个版本，则需要根据ReadView来确定。所谓ReadView，是指事务（记做事务A）在某一时刻给整个事务系统（trx_sys）打快照，之后再进行读操作时，会将读取到的数据中的事务id与trx_sys快照比较，从而判断数据对该ReadView是否可见，即对事务A是否可见。trx_sys中的主要内容，以及判断可见性的方法如下：

- low_limit_id：表示生成ReadView时系统中应该分配给下一个事务的id。如果数据的事务id大于等于low_limit_id，则对该ReadView不可见。
- up_limit_id：表示生成ReadView时当前系统中活跃的读写事务中最小的事务id。如果数据的事务id小于up_limit_id，则对该ReadView可见。
- rw_trx_ids：表示生成ReadView时当前系统中活跃的读写事务的事务id列表。如果数据的事务id在low_limit_id和up_limit_id之间，则需要判断事务id是否在rw_trx_ids中：如果在，说明生成ReadView时事务仍在活跃中，因此数据对ReadView不可见；如果不在，说明生成ReadView时事务已经提交了，因此数据对ReadView可见。

### 数据库查询流程

简单来说分为五步：

① 客户端发送一条查询给服务器。

② 服务器先检查**查询缓存**，如果命中了缓存则立刻返回存储在缓存中的结果，否则进入下一阶段。

③ 服务器端进行 SQL **解析**、**预处理**，再由优化器生成对应的**执行计划**。

④ MySQL 根据优化器生成的执行计划，调用存储引擎的 API 来执行查询。

⑤ 将结果返回给客户端。

## 数据类型

### VARCHAR 和 CHAR 的区别

**VARCHAR** 用于存储可变字符串，是最常见的字符串数据类型。它比 CHAR 更节省空间，因为它仅使用必要的空间。**VARCHAR 需要 1 或 2 个额外字节记录字符串长度**，如果列的最大长度不大于 255 字节则只需要 1 字节。**VARCHAR 不会删除末尾空格**。

VARCHAR 适用场景：字符串列的最大长度比平均长度大很多、列的更新很少、使用了 UTF8 这种复杂字符集，每个字符都使用不同的字节数存储。

**CHAR** 是定长的，根据定义的字符串长度分配足够的空间。CHAR **会删除末尾空格**。

CHAR 适合存储很短的字符串，或所有值都接近同一个长度，例如存储密码的 MD5 值。**对于经常变更的数据，CHAR 也比 VARCHAR更好，因为定长的 CHAR 不容易产生碎片**。**对于非常短的列，CHAR 在存储空间上也更有效率**，例如用 CHAR 来存储只有 Y 和 N 的值只需要一个字节，但是 VARCHAR 需要两个字节，因为还有一个记录长度的额外字节。

### DATETIME 和 TIMESTAMP 的区别

**DATETIME** **能保存大范围的值**，从 1001~9999 年，精度为秒。把日期和时间封装到了一个整数中，**与时区无关**，**使用 8 字节存储空间**。**TIMESTAMP** 和 UNIX 时间戳相同，**只使用 4 字节的存储空间**，**范围比 DATETIME 小得多**，只能表示1970 ~2038 年，并且**依赖于时区**。

### 数据类型优化策略

**更小的通常更好**

一般情况下尽量使用可以正确存储数据的最小数据类型，更小的数据类型通常也更快，因为它们占用更少的磁盘、内存和 CPU 缓存。

**数据类型尽可能简单**

简单数据类型的操作通常需要更少的 CPU 周期，例如整数比字符操作代价更低，因为字符集和校对规则使字符相比整形更复杂。应该使用 MySQL 的内建类型 date、time 和 datetime 而不是字符串来存储日期和时间，另一点是应该使用整形存储 IP 地址。

**尽量避免** **NULL**

通常情况下最好指定列为 NOT NULL，除非需要存储 NULL值。因为如果**查询中包含可为 NULL 的列对MySQL 来说更难优化**，可为 NULL 的列使索引、索引统计和值比较都更复杂，并且会使用更多存储空间。当可为 NULL 的列被索引时，每个索引记录需要一个额外字节，在MyISAM 中还可能导致固定大小的索引变成可变大小的索引。如果计划在列上建索引，就应该尽量避免设计成可为 NULL 的列。

## 索引

> 参考资料：https://zhuanlan.zhihu.com/p/29118331

索引也叫键，是存储引擎用于快速找到记录的一种数据结构。对于非常小的表，大部分情况下会采用全表扫描。对于中到大型的表，索引就非常有效。但对于特大型的表，建立和使用索引的代价也随之增长，**这种情况下应该使用分区技术**。应该只为最经常查询和最经常排序的数据列建立索引。

常用索引有：

- B-Tree索引（基于B+树）
- 聚簇索引
- 哈希索引
- 空间索引
- 全文索引

索引类型有：

- 普通索引：这是最基本的索引，它没有任何限制。普通索引（由关键字KEY或INDEX定义的索引）的唯一任务是加快对数据的访问速度。
- 唯一索引：它与前面的普通索引类似，但唯一索引列的值必须唯一，但允许有空值。如果是组合索引，则列值的组合必须唯一。
- 主键索引：它是一种特殊的唯一索引，不允许有空值。一个表只能有一个主键。一般是在建表的时候同时创建主键索引。
- 组合索引：几列组成的索引

### 索引排序

MySQL中，有两种方式生成**有序结果集**：

- 使用filesort
- 按索引顺序扫描

如果explain出来的type列的值为“index”，则说明MYSQL使用了索引扫描来做排序。

索引是在存储引擎中实现的，而不是在服务器层中实现的。所以，每种存储引擎的索引都不一定完全相同，并不是所有的存储引擎都支持所有的索引类型。

#### 索引顺序扫描

- 当索引的顺序与ORDER BY中的列顺序相同，且所有的列是同一方向（全部升序或者全部降序）时，可以使用索引来排序。
- ORDER BY子句和查询型子句的限制是一样的：需要满足索引的**最左前缀**的要求，有一种情况下ORDER BY子句可以不满足索引的最左前缀要求，那就是前导列为常量时：WHERE子句或者JOIN子句中对前导列指定了常量。
- 如果查询是连接多个表，仅当ORDER BY中的所有列都是第一个表的列时才会使用索引。其它情况都会使用filesort文件排序。

<img src="../../../E/typora/Pictures/v2-19d7202ee71287a606f644837d0c19cc_720w.jpg" alt="img" style="zoom:67%;" />

#### filesort

**当MySQL不能使用索引进行排序时，就会利用自己的排序算法(快速排序算法)在内存(sort buffer)中对数据进行排序**；

如果内存装载不下，它会将磁盘上的数据进行分块，再对各个数据块进行排序，然后将各个块合并成有序的结果集（实际上就是外排序，使用临时表）。

对于**filesort**，MySQL有两种排序算法：

- **两次扫描算法(Two passes)**

  先将需要排序的字段和可以直接定位到相关行数据的指针信息取出，然后在设定的内存（通过参数sort_buffer_size设定）中进行排序，完成排序之后再次通过行指针信息取出所需的Columns。

  该算法是MySQL4.1之前采用的算法，它需要两次访问数据，尤其是第二次读取操作会导致大量的随机I/O操作。另一方面，内存开销较小。

- **一次扫描算法(single pass)**

  该算法一次性将所需的Columns全部取出，在内存中排序后直接将结果输出。

  从MySQL4.1版本开始使用该算法。它减少了I/O的次数，效率较高，但是内存开销也较大。如果我们将并不需要的Columns也取出来，就会极大地浪费排序过程所需要的内存。

在 MySQL 4.1 之后的版本中，可以通过设置 max_length_for_sort_data 参数来控制 MySQL 选择第一种排序算法还是第二种：当取出的所有大字段总大小大于 max_length_for_sort_data 的设置时，MySQL 就会选择使用第一种排序算法，反之，则会选择第二种。

### 聚簇索引

一个表只能有一个聚簇索引。目前，只有solidDB和InnoDB支持聚簇索引，MyISAM不支持聚簇索引。

#### InnoDB的聚簇索引

1. InnoDB对主键建立聚簇索引。
2. 如果你不指定主键，InnoDB会用一个具有唯一且非空值的索引来代替。
3. 如果不存在这样的索引，InnoDB会定义一个隐藏的主键，然后对其建立聚簇索引。

一般来说，DBMS都会以聚簇索引的形式来存储实际的数据，它是其它二级索引的基础：

- 聚簇索引（primary索引）：主键索引
- 非聚簇索引（second索引）：二级索引

<img src="../../../E/typora/Pictures/v2-ee2277c868c80bac6d3526e647de8e41_720w.jpg" alt="img" style="zoom: 80%;" />

#### 聚簇索引结构

**聚簇索引：**节点页只包含了索引列，叶子页包含了行的全部数据。聚簇索引“就是表”，因此可以不需要独立的行存储。

**二级索引：**叶子节点保存的不是指行的物理位置的指针，而是行的主键值。

聚簇索引保证关键字的值相近的元组存储的物理位置也相近（所以字符串类型不宜建立聚簇索引，特别是随机字符串，会使得系统进行大量的移动操作）。

```mysql
CREATE TABLE layout_test (
  col1 int NOT NULL, # 主键索引，在InnoDB中同时为聚簇索引
  col2 int NOT NULL, # 非主键索引，在InnoDB中同时为二级索引
  PRIMARY KEY(col1),
  KEY(col2)
);
```

<img src="../../../E/typora/Pictures/v2-1a2aa27dbe33463dd42f0585d2504e3d_720w.jpg" alt="img" style="zoom:80%;" />

- 在MyISAM中

因为元组的大小固定，所以MyISAM可以很容易的从表的开始位置找到某一字节的位置。（所以可能只存储行号就可以了）

col1主键索引：

MyISAM不支持聚簇索引，索引中每一个叶子节点仅仅包含行号(row number)，且叶子节点按照col1的顺序存储。

<img src="../../../E/typora/Pictures/v2-e5622d317fe702269cf05973dcc36b7e_720w.jpg" alt="img" style="zoom:80%;" />

col2非主键索引：

在MyISAM中，primary key和其它索引没有什么区别。Primary key仅仅只是一个叫做PRIMARY的唯一，非空的索引而已，叶子节点按照col2的顺序存储。

<img src="../../../E/typora/Pictures/v2-1c672e22e1d629c651cda207c7b02352_720w.jpg" alt="img" style="zoom:80%;" />

- 在InnoDB中

col1主键索引，即聚簇索引：

聚簇索引中的每个叶子节点包含主键的值，事务ID，用于事务和MVCC的回滚指针，和余下的列(如col2)。

<img src="../../../E/typora/Pictures/v2-f20aa7e23a8662b4054b24bc7f86f66c_720w.jpg" alt="img" style="zoom:80%;" />

col2非主键索引，即二级索引：

InnoDB的二级索引的**叶子包含主键的值，而不是行指针(row pointers)**，这样的策略减小了移动数据或者数据页面分裂时维护二级索引的开销，因为InnoDB不需要更新索引的行指针。

<img src="../../../E/typora/Pictures/v2-28008f3730c8546c1e11bbdac88c92dc_720w.jpg" alt="img" style="zoom:80%;" />

#### 覆盖索引

> 参考资料：https://juejin.cn/post/6844903967365791752

覆盖索引（covering index ，或称为索引覆盖）即从非主键索引中就能查到的记录，而不需要查询主键索引中的记录，避免了回表的产生减少了树的搜索次数，显著提升性能。

name和age两个字段建立联合索引，sql命令与建立后的索引树结构如下：

<img src="../../../E/typora/Pictures/16dd033b2a2c7c24" alt="img" style="zoom:67%;" />

执行如下sql后

```mysql
SELECT age FROM student WHERE name = '小李'；
```

流程为：

1. 在name,age联合索引树上找到名称为小李的节点
2. 此时节点索引里包含信息age 直接返回 12

#### 聚簇索引的优点

1. 聚簇索引将索引和数据行保存在同一个B-Tree中，查询通过聚簇索引可以直接获取数据，而**非聚簇索引要进行多次I/O**，所以聚簇索引通常比非聚簇索引查找更快。
2. 聚簇索引对主键范围查询的效率很高，因为其数据是按照主键排列的
3. 二级索引使用索引覆盖可以直接使用叶节点的主键值。

### Hash索引

哈希索引基于哈希表实现，**只有精确索引所有列的查询才有效**。

MySQL中，只有Memory存储引擎显示支持hash索引，是Memory表的默认索引类型，Memory存储引擎支持非唯一hash索引，如果多个值有相同的hash code，索引把它们的行指针用链表保存到同一个hash表项中。

索引的结构大概如下（第一列是哈希值，第二列是对应行的指针）：

<img src="../../../E/typora/Pictures/v2-043d10a60fcc2a4a5ee9d696a7537cae_720w.jpg" alt="img" style="zoom: 67%;" />

**Hash索引有以下一些限制：**

- 由于索引仅包含hash code和记录指针，所以，MySQL不能通过使用索引避免读取记录，即每次使用哈希索引查询到记录指针后都要回读元祖查取数据。
- **不能使用hash索引排序**。
- Hash索引**不支持键的部分匹配**，因为是通过整个索引值来计算hash值的。
- Hash索引**只支持等值比较**，例如使用=，IN( )和<=>。对于WHERE price>100并不能加速查询。
- 访问Hash索引的速度非常快，除非有很多哈希冲突（不同的索引列值却有相同的哈希值）。当出现哈希冲突的时候，存储引擎必须遍历链表中所有的行指针，逐行进行比较，直到找到所有符合条件的行。
- 如果哈希冲突很多的话，一些索引维护操作的代价也会很高。当从表中删除一行时，存储引擎要遍历对应哈希值的链表中的每一行，找到并删除对应行的引用，冲突越多，代价越大。

### 空间(R-Tree)索引

MyISAM支持空间索引，主要用于地理空间数据类型，例如GEOMETRY。

### 全文(Full-text)索引

MySQL InnoDB从5.6开始已经支持全文索引，全文索引是MyISAM的一个特殊索引类型，它查找的是**文本中的关键词**，主要用于全文检索。

### 索引性能优化

> 参考资料：
>
> https://zhuanlan.zhihu.com/p/29118331
>
> https://zhuanlan.zhihu.com/p/88963084

#### 建立索引的时机

- 为经常需要**排序**（order by）、**分组**（group by）和**联合操作**（join）的字段建立索引。

- 为常作为**查询条件**（where）的字段建立索引。

- 尽量的扩展索引，不要新建索引。

#### 索引设计

1. 索引字段尽量使用数字型（简单的数据类型）

2. 尽量不要让字段的默认值为NULL

3. 对串列进行索引，如果可能应该指定一个**前缀长度**。

4. 索引的选择性是指，不重复的索引值（基数）和数据表中的记录总数的比值。要选择足够长的前缀以保证较高的选择性，同时又不能太长（以便节约空间）。

5. 尽量使用唯一索引

6. 使用组合索引代替多个列索引

7. 删除重复/冗余的索引、不使用的索引
8. 索引应该建在小字段上，不要建在超长文本上

#### 索引使用

1. 如果对大的文本进行搜索，使用全文索引而不要用使用 like ‘%…%’

2. like语句不要以通配符开头，通配符开头的语句不会被索引

3. 不要在索引列上进行运算。索引列不能是表达式的一部分，也不是是函数的参数。

4. 尽量不要使用NOT IN、<>（不等于号的正确用法）、!= 操作，否则将引擎放弃使用索引而进行全表扫描。

   - 对于not in，可以用not exists或者（外联结+判断为空）来代替
   - 对于<>，用其它相同功能的操作运算代替，如a<>0 改为 a>0 or a<0

5. 应尽量避免在 where 子句中使用 or 来连接条件，用 or 分割开的条件， 如果 or 前的条件中的列有索引， 而后面的列中没有索引， 那么涉及到的索引都不会被用到。

   > 应尽量避免在 where 子句中使用 or 来连接条件，否则将导致引擎放弃使用索引而进行全表扫描，如： 假设num1有索引，num2没有索引，查询语句select id from t where num1=10 or num2=20会放弃使用索引，可以改为这样查询： select id from t where num1=10 union all select id from t where num2=20，这样虽然num2没有使用索引，但至少num1会使用索引，提高效率。

6. 对于组合索引，当不需要考虑排序和分组时，将选择性最高的列放在前面通常是最好的

7. 查询必须从索引的最左边的列开始，否则无法使用索引。

8. 不能跳过某一索引列。

9. 存储引擎不能使用索引中范围条件右边的列。

   > 例如，如果你的查询语句为WHERE **last_name**="Smith" AND **first_name** LIKE 'J%' AND **dob**='1976-12-23'，则该查询只会使用索引中的前两列，因为LIKE是范围查询。

10 . 如果列类型是字符串，那么一定记得在 where 条件中把字符常量值用引号引起来，否则的话即便这个列上有索引，MySQL 也不会用到的，因为MySQL 默认把输入的常量值进行转换以后才进行检索（因为不加引号则会将284看成数值）.

```mysql
select * from company where name = '284'\G
```

11. 任何地方都不要使用 `select * from t` ，用具体的**字段列表**代替“*”，不要返回用不到的任何字段

12. 如果 MySQL 估计使用索引比全表扫描更慢，则不使用索引。

13. 用>=替代>

    > 高效: SELECT * FROM EMP WHERE DEPTNO >=4
    >
    > 低效: SELECT * FROM EMP WHERE DEPTNO >3
    >
    > 两者的区别在于, 前者DBMS将直接跳到第一个DEPT等于4的记录，而后者将首先定位到DEPTNO=3的记录并且向前扫描到第一个DEPT大于3的记录。

## MySQL优化

> 参考资料：https://segmentfault.com/a/1190000012155267

1. SQL语句中IN包含的值不应过多

2. SELECT语句务必指明字段名称。

   > SELECT *增加很多不必要的消耗（cpu、io、内存、网络带宽）

3. 当只需要一条数据的时候，使用limit 1

   > 这是为了使EXPLAIN中type列达到const类型

4. 如果排序字段没有用到索引，就尽量少排序

5. 如果限制条件中其他字段没有索引，尽量少用or

   > or两边的字段中，如果有一个不是索引字段，而其他条件也不是索引字段，会造成该查询不走索引的情况。很多时候使用 union all 或者是union(必要的时候)的方式来代替“or”会得到更好的效果

6. 尽量用union all代替union

   > union和union all的差异主要是前者需要将结果集合并后再进行唯一性过滤操作，这就会涉及到排序，增加大量的CPU运算，加大资源消耗及延迟。**当然，union all的前提条件是两个结果集没有重复数据。**

7. 区分使用in和exists

   > **IN适合于外表大而内表小的情况；EXISTS适合于外表小而内表大的情况。**

8. 使用合理的分页方式以提高分页的效率

   > ```mysql
   > lect id,name from table_name limit 866613, 20
   > ```
   >
   > 使用上述sql语句做分页的时候，可能有人会发现，随着表数据量的增加，直接使用limit分页查询会越来越慢。
   >
   > 优化的方法如下：可以取前一页的最大行数的id，然后根据这个最大的id来限制下一页的起点。比如此列中，上一页最大的id是866612。sql可以采用如下的写法：
   >
   > ```mysql
   > select id,name from table_name where id> 866612 limit 20
   > ```

9. 分段查询（使用between分段）

   > 在一些用户选择页面中，可能一些用户选择的时间范围过大，造成查询缓慢。主要的原因是扫描行数过多。这个时候可以通过程序，分段进行查询，循环遍历，将结果合并处理进行展示。

10. 避免在 where 子句中对字段进行 null 值判断

    > 对于null的判断会导致引擎放弃使用索引而进行全表扫描。

11. 不建议使用%前缀模糊查询

12. 避免在where子句中对字段进行表达式操作

13. 避免隐式类型转换

14. 对于联合索引来说，要遵守最左前缀法则

15. 必要时可以使用force index来强制查询走某个索引

16. 注意范围查询语句会使后面的索引失效

## 复制

**复制解决的基本问题是让一台服务器的数据与其他服务器保持同步**，一台主库的数据可以同步到多台备库上，备库本身也可以被配置成另外一台服务器的主库。主库和备库之间可以有多种不同的组合方式。

MySQL 支持两种复制方式：**基于行的复制**和**基于语句的复制**，基于语句的复制也称为逻辑复制，从MySQL 3.23 版本就已存在，基于行的复制方式在 5.1 版本才被加进来。这两种方式都是通过**在主库上记录二进制日志**、**在备库重放日志**的方式来实现异步的数据复制。因此同一时刻备库的数据可能与主库存在不一致。

复制解决的问题：数据分布、负载均衡、备份、高可用性和故障切换、MySQL 升级测试。

# SQL

## exists和in

**in()是在内存里遍历,而exists()需要查询数据库**

外层查询表小于子查询表，则用exists，外层查询表大于子查询表，则用in，如果外层和子查询表差不多，则爱用哪个用哪个。

**In关键字原理**

```mysql
SELECT * FROM `user`  
    WHERE id in (SELECT user_id FROM `order`)
```

in()语句只会执行一次，它查出order表中的所有user_id字段并且**缓存起来**，之后，检查user表的id是否和order表中的user_id相当，如果相等则加入结果，直到遍历完user的所有记录。

order表数据很大的时候不适合用in，因为它最多会将order表数据全部遍历一次。

假如user表有10000条记录,order表有1000000条记录,那么最多有可能遍历10000*1000000次,效率很差。

**exists关键字原理**

```mysql
SELECT * FROM `user` 
    WHERE exists (SELECT * FROM `order` WHERE user.id = order.user_id)
```

exists用于检查子查询是否至少会返回一行数据，该子查询实际上并不返回任何数据，而是返回值**True**或**False**。

当子查询返回为真时，则外层查询语句将进行查询。

当子查询返回为假时，外层查询语句将不进行查询或者查询不出任何记录。

因此上面的SQL语句旨在搜索出**所有下过单的会员**。需要注意的是，当我们的子查询为 SELECT NULL 时，MYSQL仍然认为它是**True**。

exists语句会执行user.length次，它并**不会去缓存exists的结果集**，因为这个结果集并不重要

假如user表有10000条记录,order表有1000000条记录,那么exists()会执行10000次去判断user表中的id是否与order表中的user_id相等

## IF表达式

如果 expr1 是TRUE (expr1 <> 0 and expr1 <> NULL)，则 IF()的返回值为expr2; 否则返回值则为 expr3。IF() 的返回值为数字值或字符串值，具体情况视其所在语境而定。

```mysql
IF(expr1,expr2,expr3)
```

```mysql
update salary set sex = if(sex = 'f', 'm', 'f')
```

也可以用case when代替：

```mysql
update salary
set sex = 
case sex 
    when 'f'
    then 'm'
    else 'f'
end
```



## Union复合查询

复合查询适用于下面两种情境中：

1. 从多个表中查询出相似结构的数据，并且返回一个结果集
2. 从单个表中多次`SELECT`查询，将结果合并成一个结果集返回。

复合查询使用规则：

1. `Union`必须由两条或者两条以上的`SELECT`语句组成，语句之间使用`Union`链接。
2. `Union`中的每个查询必须包含相同的列、表达式或者聚合函数，他们出现的顺序可以不一致（这里指查询字段相同，表不一定一样）
3. 列的数据类型必须兼容，兼容的含义是必须是数据库可以隐含的转换他们的类型

user表内容：

<img src="../../../E/typora/Pictures/bVHpA1" alt="图片描述" style="zoom:67%;" />

posts表内容：

<img src="../../../E/typora/Pictures/bVHqac" alt="图片描述" style="zoom: 67%;" />

查询结果：

```mysql
select posts_id,posts_name,posts_status,'users' as table_name from yy_posts
UNION
select user_id,user_nickname,user_status,'posts' as table_name from yy_user
```

<img src="../../../E/typora/Pictures/bVHqdC" alt="图片描述" style="zoom:67%;" />

使用`Union`组合查询时，只能使用一条`order by`子句对结果集进行排序，而且必须出现在最后一条出现的`SELECT`语句之后。因为`Union`不允许对于部分结果集进行排序，只能针对最终检索出来的结果集进行排序。

可以使用`Union All`操作符来取消自动合并功能。

## limit子句

> 参考资料：https://segmentfault.com/a/1190000008859706

**LIMIT 接受一个或两个数字参数**。参数必须是一个整数常量。如果给定一个参数n，则是取出前面的n行查询结果。如果给定两个参数，**第一个参数**指定第一个返回记录行的**偏移量**，**第二个参数**指定**返回记录行的最大数目**。初始记录行的偏移量是 0(而不是 1)。了检索从某一个偏移量到记录集的结束所有的记录行，可以指定第二个参数为 -1。

实际应用中，可以利用类似**策略模式**的方式去处理分页，比如判断如果是一百页以内，就使用最基本的分页方式，大于一百页，则使用子查询的分页方式。

```mysql
SQL代码1：平均用时6.6秒 SELECT * FROM `cdb_posts` ORDER BY pid LIMIT 1000000 , 30

SQL代码2：平均用时0.6秒 SELECT * FROM `cdb_posts` WHERE pid >= (SELECT pid FROM  
`cdb_posts` ORDER BY pid LIMIT 1000000 , 1) LIMIT 30
```

## mysql排序

### row_number

row_number会为查询出来的每条记录生成一个序号，依次排序并且不会重复，row_number必须要使用over句子选择对某一列进行排序才会生成序号，row_number用法实例：

```mysql
select SubTime, ROW_NUMBER() OVER(order by SubTime desc) as row_num from Order
```

### rank

rank函数与row_number函数不同的一点就是考虑到了over子句中排序字段值相同的情况，over子句中排序字段值相同的序号是一样的，后面字段值不相同的序号将跳过相同的排名号排下一个，所以其生成序号可能是不连续的

```mysql
select RANK() OVER(order by UserId) as rank from Order
```

### dense_rank

dense_rank与rank函数不同的是，不会跳过相同排名号的下一个，而是会产生连续的序号，其用法如下：

```mysql
select DENSE_RANK() OVER(order by UserId) as den_rank from Order
```

# NoSQL

**NoSQL数据库的存储模型**：列存储数据库（HBASE），键值存储数据库（Redis），文档存储数据库（MongoDB），图存储数据库（Neo4J）

## 分布式环境的三个核心需求（CAP）与BASE

**CAP：**一致性（Consistency），可用性（Availability），分区容忍性（Partition Tolerance）

一个分布式系统不可能同时满足三个要求，最多只能同时较好的满足两个：

CA - 单点集群，满足一致性，可用性的系统

CP - 满足一致性，分区容忍性的系统

AP - 满足可用性，分区容忍性的系统



**BASE（AP的衍生）：**

Basically Available --**基本可用**；系统能够基本运行，一直提供服务。

Soft-state --**软状态/柔性事务**。"Soft state" 可以理解为"无连接"的, “软状态”是指状态可以有一段时间不同步，具有一定的滞后性，而 "Hard state" 是"面向连接"的；系统不要求一直保持强一致状态。 

Eventual Consistency --**最终一致性** 系统在某个时刻达到最终一致性。

# Redis

1. Redis运行在内存中但是可以持久化到磁盘，相比在磁盘上相同的复杂的数据结构，在内存中操作起来非常简单
2. Redis 大小写敏感
3. Redis 使用**单线程架构**和 **非阻塞IO 多路复用**模型实现高性能的内存数据库服务。每次客户端调用都经历了发送命令、执行命令、返回结果三个过程，因为 Redis 是单线程处理命令的，所以一条命令从客户端到达服务器不会立即执行，所有命令都会进入一个队列中逐个执行。网络层使用epoll解决高并发问题，单线程模型避免了不必要的上下文切换及竞争条件。客户端的执行顺序不确定，但确定不会有两条命令同时执行，不存在并发问题。
4. 数据量太大、数据访问频率非常低的业务都不适合使用Redis

**Redis为什么设计为单线程**

Redis是内存数据库不涉及I/O操作，因此设计为单线程是效率最高的，可以避免了不必要的上下文切换及竞争条件

## Redis特点

Redis 与其他 key - value 缓存产品有以下三个特点：

- Redis**支持数据的持久化**，可以将内存中的数据保存在磁盘中，重启的时候可以再次加载进行使用。
- Redis**有丰富的数据结构**，不仅仅支持简单的key-value类型的数据，同时还提供list，set，zset，hash等数据结构的存储。
- Redis**支持数据的备份**，即master-slave模式的数据备份。

## Redis优势

- **性能极高** – Redis能读的速度是110000次/s,写的速度是81000次/s 。
- **丰富的数据类型** – Redis支持二进制案例的 Strings, Lists, Hashes, Sets 及 Ordered Sets 数据类型操作。
- **原子性** – Redis的所有操作都是原子性的，意思就是要么成功执行要么失败完全不执行。单个操作是原子性的。多个操作也支持事务，即原子性，通过MULTI和EXEC指令包起来。
- **丰富的特性** – Redis还支持 publish/subscribe, 通知, key 过期等等特性。

## Redis的使用

以下操作需要在安装redis的目录中运行（除非设置了环境变量）

**启动服务器**

```cmd
redis-server.exe redis.windows.conf  %可以省略redis.windows.conf%
```

**启动客户端**

```cmd
redis-cli.exe -h 127.0.0.1 -p 6379 %如果连接本地则可以省略ip地址和端口号%
```

设置键值对

```shell
set myKey abc
```

查询键值对

```shell
get myKey
```

## Redis数据结构

Redis有五种数据结构：

- String: 字符串
- Hash：哈希
- List：列表
- Set：集合
- Sorted Set（又称zset）：有序集合

### String字符串

- string 是 redis 最基本的类型，一个 key 对应一个 value。string 类型的值最大能存储 512MB。

- string 类型是**二进制安全的**。意思是 redis 的 string 可以包含任何数据。比如jpg图片或者序列化的对象。

**实例**

```cmd
redis 127.0.0.1:6379> SET runoob "菜鸟教程"
OK
redis 127.0.0.1:6379> GET runoob
"菜鸟教程"
```

### Hash哈希

Redis hash 是一个 **string 类型的 field 和 value 的映射表**，hash 特别适合用于存储对象。

**实例**

```cmd
redis 127.0.0.1:6379> HMSET runoob field1 "Hello" field2 "World"
"OK"
redis 127.0.0.1:6379> HGET runoob field1
"Hello"
redis 127.0.0.1:6379> HGET runoob field2
"World"
```

### List列表（双向链表）

Redis 列表是简单的字符串列表，按照插入顺序排序。你可以添加一个元素到列表的头部（左边）或者尾部（右边）。

**实例**

```cmd
redis 127.0.0.1:6379> lpush runoob redis
(integer) 1
redis 127.0.0.1:6379> lpush runoob mongodb
(integer) 2
redis 127.0.0.1:6379> lpush runoob rabbitmq
(integer) 3
redis 127.0.0.1:6379> lrange runoob 0 10
1) "rabbitmq"
2) "mongodb"
3) "redis"
```

### Set集合

Redis 的 Set 是 string 类型的无序集合。

集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是 O(1)。

通过`sadd`命令添加一个 string 元素到 key 对应的 set 集合中，成功返回 1，如果元素已经在集合中返回 0。

**实例**

```cmd
redis 127.0.0.1:6379> sadd runoob redis
(integer) 1
redis 127.0.0.1:6379> sadd runoob mongodb
(integer) 1
redis 127.0.0.1:6379> sadd runoob rabbitmq
(integer) 1
redis 127.0.0.1:6379> sadd runoob rabbitmq
(integer) 0
redis 127.0.0.1:6379> smembers runoob
1) "redis"
2) "rabbitmq"
3) "mongodb"
```

### Zset有序集合

Redis zset 和 set 一样也是string类型元素的集合,且不允许重复的成员。

不同的是每个元素都会**关联一个double类型的分数**。redis正是通过分数来为集合中的成员进行从小到大的排序。

zset的**成员是唯一的**,但**分数(score)却可以重复**。

通过`zadd`命令添加元素到集合，元素在集合中存在则更新对应score

**实例**

```cmd
redis 127.0.0.1:6379> zadd runoob 0 redis
(integer) 1
redis 127.0.0.1:6379> zadd runoob 0 mongodb
(integer) 1
redis 127.0.0.1:6379> zadd runoob 0 rabbitmq
(integer) 1
redis 127.0.0.1:6379> zadd runoob 0 rabbitmq
(integer) 0
redis 127.0.0.1:6379> ZRANGEBYSCORE runoob 0 1000
1) "mongodb"
2) "rabbitmq"
3) "redis"
```

## Redis 基础命令

**DEL key**

用于删除键

**DUMP key**

返回序列化后的键值

**EXISTS key**

检查键是否存在

**KEYS pattern**

查找所有符合对应模式的key

可以使用`KEYS *`返回数据库中所有的key

**SELECT index**

切换到对应下标的数据库（Redis的数据库以0开始的下标标识）

**Move key db**

将当前数据库的key移动到对应数据库去

**RANDOMKEY**

随机返回一个数据库中的key名

**RENAME key newky**

重命命名key名

**RENAMENX key newkey**

仅当 newkey 不存在时，将 key 改名为 newkey 。

**SCAN cursor [MATCH pattern] [COUNT count]**

- cursor - 游标。
- pattern - 匹配的模式。
- count - 指定从数据集里返回多少元素，**默认值为 10** 。

用于迭代数据库中的数据库键

SCAN 命令是一个基于游标的迭代器，每次被调用之后， 都会向用户**返回一个新的游标**， 用户在下次迭代时需要使用这个新游标作为 SCAN 命令的游标参数， 以此来延续之前的迭代过程。

SCAN 返回一个包含两个元素的数组， 第一个元素是用于进行下一次迭代的新游标， 而第二个元素则是一个数组， 这个数组中包含了所有被迭代的元素。如果**新游标返回 0 表示迭代已结束**。

**TYPE key**

返回key所存储值的类型

## 基数统计HyperLogLog

**什么是基数**

比如数据集 {1, 3, 5, 7, 5, 7, 8}， 那么这个数据集的基数集为 {1, 3, 5 ,7, 8}, **基数(不重复元素)**为5。 基数估计就是在误差可接受的范围内，快速计算基数。



Redis HyperLogLog 是用来做基数统计的算法，HyperLogLog 的优点是，在输入元素的数量或者体积非常非常大时，计算基数所需的**空间总是固定的、并且是很小的**。和计算基数时，元素越多耗费内存就越多的集合形成鲜明对比。



**相关命令**：

**PFADD key element**

添加指定元素到HyperLogLog中

**PFCOUNT key**

返回给定HyperLogLog的基数的估算值

**PFMERGE destkey sourcekey [sourcekey]**

将destkey和各个sourcekey中的HyperLogLog合并入destkey中，destkey不一定需要存在，sourcekey的值不会消失。

## 订阅

Redis 发布订阅 (pub/sub) 是一种消息通信模式：发送者 (pub) 发送消息，订阅者 (sub) 接收消息。Redis 客户端可以订阅任意数量的频道。

通过` SUBSCRIBE channelName`订阅频道，通过`UNSUBSCRIBE channelName`退订频道，通过`PUBLISH channelName message`发布信息

<img src="../../../E/typora/Pictures/pubsub1.png" alt="img" style="zoom: 67%;" />

<img src="../../../E/typora/Pictures/pubsub2.png" alt="img" style="zoom:67%;" />

## 事务

Redis 事务可以一次执行多个命令， 并且带有以下三个重要的保证：

- 批量操作在发送MULTI命令后发送 EXEC 命令前被放入队列缓存。
- 收到 EXEC 命令后进入事务执行，事务中任意命令执行失败，**其余的命令依然被执行**。
- 在事务执行过程，其他客户端提交的命令请求不会插入到事务执行命令序列中。

```cmd
redis 127.0.0.1:6379> MULTI
OK

redis 127.0.0.1:6379> SET book-name "Mastering C++ in 21 days"
QUEUED

redis 127.0.0.1:6379> GET book-name
QUEUED

redis 127.0.0.1:6379> SADD tag "C++" "Programming" "Mastering Series"
QUEUED

redis 127.0.0.1:6379> SMEMBERS tag
QUEUED

redis 127.0.0.1:6379> EXEC
1) OK
2) "Mastering C++ in 21 days"
3) (integer) 3
4) 1) "Mastering Series"
   2) "C++"
   3) "Programming"
```

**单个 Redis 命令的执行是原子性**的，但 Redis 没有在事务上增加任何维持原子性的机制，所以 **Redis 事务的执行并不是原子性**的。事务可以理解为一个打包的批量执行脚本，但批量指令并非原子化的操作，中间某条指令的失败不会导致前面已做指令的回滚，也不会造成后续的指令不做。

# 分库分表

> 参考资料：https://juejin.cn/post/6844903648670007310

## 数据库架构演变

刚开始我们只用单机数据库就够了，随后面对越来越多的请求，我们将数据库的**写操作和读操作进行分离**， 使用多个**从库副本（Slaver Replication）负责读**，使用**主库（Master）负责写**， **从库从主库同步更新数据**，保持数据一致。架构上就是数据库主从同步。 从库可以**水平扩展**，所以更多的读请求不成问题。

## 分库分表前问题的解决

**用户请求太多**

问题：因为单服务器TPS，内存，IO都是有限的。

解决方法：分散请求到多个服务器上

**单库太大**

问题：单个数据库处理能力有限；单库所在服务器上磁盘空间不足；单库上操作的IO瓶颈  

解决方法：分成更多更小的库

**单表太大**

问题：CRUD都成问题；**索引膨胀**，查询超时

解决方法：切分成多个数据集更小的表

## 垂直分表

也就是“大表拆小表”，基于列字段进行的。一般是表中的字段较多，将**不常用的**， **数据较大**，**长度较长**（比如text类型字段）的字段拆分到“扩展表“。

## 垂直分库

垂直分库针对的是一**个系统中的不同业务进行拆分**，比如用户User一个库，商品Producet一个库，订单Order一个库。 切分后，**要放在多个服务器上**，而不是一个服务器上。

## 水平分表

针对数据量巨大的单张表（比如订单表），**按照某种规则（RANGE,HASH取模等），切分到多张表里面去**。 但是这些表还是在同一个库中，所以库级别的数据库操作还是有IO瓶颈。不建议采用。

## 水平分库分表

将单张表的数据切**分到多个服务器上去**，**每个服务器具有相应的库与表**，只是表中数据集合不同。 水平分库分表能够有效的缓解单机和单库的性能瓶颈和压力，突破IO、连接数、硬件资源等的瓶颈。

### 水平分库分表切分规则

1. **RANGE**

   从0到10000一个表，10001到20000一个表；

2. **HASH取模**

   一个商场系统，一般都是将用户，订单作为主表，然后将和它们相关的作为附表，这样不会造成跨库事务之类的问题。 取用户id，然后hash取模，分配到不同的数据库上。

3. **地理区域**

   比如按照华东，华南，华北这样来区分业务，七牛云应该就是如此。

4. **时间**

   按照时间切分，就是将6个月前，甚至一年前的数据切出去放到另外的一张表，因为随着时间流逝，这些表的数据 被查询的概率变小，所以没必要和“热数据”放在一起，这个也是“冷热数据分离”。

## 分库后跨库join的粗略解决方法

1. 全局表：基础数据所有库都拷贝一份
2. 字段冗余：有些字段就不需要join查询了
3. 系统层组装，分别查询出所有，然后组装起来，比较复杂

# 数据库规范化

未优化的关系模式可能存在的问题：插入异常，删除异常，冗余，更新异常

异常现象的根源：关系模式存在着一些数据依赖关系

需要对数据库规范化，优化关系模式，提高数据管理效率

## 数据依赖

数据依赖： 指通过关系模式**某些属性的取值能够决定另一些属性的取值**

数据依赖分类：函数依赖，多值依赖

### 函数依赖

<img src="../../../E/typora/Pictures/image-20210122162028650.png" alt="image-20210122162028650" style="zoom:67%;" />

<img src="../../../E/typora/Pictures/image-20210122162047773.png" alt="image-20210122162047773" style="zoom:67%;" />

<img src="../../../E/typora/Pictures/image-20210122162056402.png" alt="image-20210122162056402" style="zoom:67%;" />

<img src="../../../E/typora/Pictures/image-20210122162103728.png" alt="image-20210122162103728" style="zoom:67%;" />

### 多值依赖

<img src="../../../E/typora/Pictures/image-20210122162510640.png" alt="image-20210122162510640" style="zoom:67%;" />

<img src="../../../E/typora/Pictures/image-20210122162518407.png" alt="image-20210122162518407" style="zoom:67%;" />

## 五重范式

- 超键：在关系中能唯一标识元组的属性集称为关系模式的超键。
  比如一张学生信息表，学生表中含有学号或者身份证号的任意组合都为此表的超键。如：（学号）、（学号，姓名）、（身份证号，性别）等。
- 候选键：不含有多余属性的超键称为候选键，也称为**最小超键**
  候选键属于超键，它是最小的超键，就是说如果再去掉候选键中的任何一个属性它就不再是超键了。学生表中的候选键为：（学号）、（身份证号）。
- 主属性：包含在任一候选键中的属性

<img src="../../../E/typora/Pictures/image-20210122163927091.png" alt="image-20210122163927091" style="zoom:67%;" />

<img src="../../../E/typora/Pictures/image-20210122163936327.png" alt="image-20210122163936327" style="zoom:67%;" />

<img src="../../../E/typora/Pictures/image-20210122163944460.png" alt="image-20210122163944460" style="zoom:67%;" />

<img src="../../../E/typora/Pictures/image-20210122164015784.png" alt="image-20210122164015784" style="zoom:67%;" />

<img src="../../../E/typora/Pictures/image-20210122164042965.png" alt="image-20210122164042965" style="zoom:67%;" />

<img src="../../../E/typora/Pictures/image-20210122164136836.png" alt="image-20210122164136836" style="zoom:67%;" />